%%%%% Server
allow toggleable server-mode (vim-like)

IDEA
  share choosen info between instances
  REF pipe/fifo/socket (like qutebrowser, tmux or nvim --headless)
    REF http://highered.mheducation.com/sites/0072515848/student_view0/chapter1/index.html
      2016-10-31 [X] http://highered.mheducation.com/sites/0072515848/student_view0/chapter24/index.html
        # short statements about sockets in general
    NOTE: using sockets allows us to use *core* on client and *ui* on host
    https://docs.python.org/3.5/library/socket.html
      !!! 2016-11-02 [X] READ https://docs.python.org/3/howto/sockets.html
    https://docs.python.org/3.5/library/socketserver.html
      http://stackoverflow.com/questions/20745352/creating-a-multithreaded-server-using-socketserver-framework-in-python
    https://docs.python.org/3.5/library/asyncore.html
    http://stackoverflow.com/questions/23828264/how-to-make-a-simple-multithreaded-socket-server-in-python-that-remembers-client
      https://andreymal.org/socket3/
    Shutdown gracefully -- reuse dead connection
      http://stackoverflow.com/questions/22171441/shutting-down-python-tcpserver-by-custom-handler
      = XXX server shutdown is too slow
  multithread pool
    = NEED limited pool of threads to manage fs operations
    http://asvetlov.blogspot.ru/2010/11/1.html
    https://bytes.com/topic/python/answers/44416-how-kill-socketserver
  cooperative concurrency in single thread (Python3.5 async/await)
    https://habrahabr.ru/post/266743/
    http://stackabuse.com/python-async-await-tutorial/
    http://www.snarky.ca/how-the-heck-does-async-await-work-in-python-3-5
  asyncio
    https://docs.python.org/3/library/asyncio-task.html
    https://docs.python.org/3.5/library/asyncio.html
  shared memory
    http://stackoverflow.com/questions/33535386/better-way-to-share-memory-for-multiprocessing-in-python
    http://stackoverflow.com/questions/14124588/python-multiprocessing-shared-memory
    https://habrahabr.ru/post/167503/
    https://jeffknupp.com/blog/2013/06/30/pythons-hardest-problem-revisited/
    http://semanchuk.com/philip/posix_ipc/
  socket-only server
    http://danielhnyk.cz/simple-server-client-aplication-python-3/
    !! https://www.quora.com/Does-the-TCPServer-in-Python%E2%80%99s-SocketServer-close-the-socket-after-each-call-to-handle()
    https://www.quora.com/Can-we-leave-a-socket-open-and-send-many-send-requests-without-any-problem
    https://www.quora.com/Do-TCP-sockets-queue-multiple-messages-in-a-buffer-to-be-read-one-at-a-time-Or-does-the-buffer-only-store-the-most-recently-received-message
    https://pymotw.com/2/select/
    + http://www.ual.es/~vruiz/Docencia/Apuntes/Programming/Socket_Programming/index.html
  send signal from server (G: push message / z-push)
    ++ https://www.quora.com/What-is-the-best-way-to-push-realtime-data-to-a-mobile-app
      https://www.leggetter.co.uk/real-time-web-technologies-guide/
      https://www.quora.com/topic/MQ-Telemetry-Transport-MQTT
    http://stackoverflow.com/questions/2876024/linux-is-there-a-read-or-recv-from-socket-with-timeout?rq=1
    http://stackoverflow.com/questions/3745592/python-persistent-socket-connection
    - long polling :: BAD:(deprecated by websockets) too many problems if connection lost
      = hard to process all connection errors on client side
      ++ http://moduscreate.com/fast-polling-vs-websockets-2/
      http://resthooks.org/docs/alternatives/
      https://habrahabr.ru/company/cackle/blog/167895/
      READ: Android way
        http://stackoverflow.com/questions/11508613/how-does-push-notification-technology-work-on-android
    - fast polling :: BAD: queries in cycle, has response latency
    - server-sent-events
      https://www.html5rocks.com/en/tutorials/eventsource/basics/
  discovering running client/server nodes
    http://stackoverflow.com/questions/10914750/connect-two-tcp-sockets-without-defining-client-server-role
  +++ socket simultaneous read/write
    http://stackoverflow.com/questions/11697855/python-multithreading-run-two-functions-at-the-same-time
    http://stackoverflow.com/questions/28879706/multiple-clients-cannot-listen-and-write-at-the-same-time
    https://ask.wireshark.org/questions/25591/who-send-data-first-after-tcp-connection-is-established
    ~ https://github.com/rust-lang/rust/issues/11165
    http://www.chilkatforum.com/questions/7150/socket-is-locked-internally-while-waiting-for-some-data-and-we-are-not-able-to-send-data-at-the-same-time-from-another-thread
    - http://blog.davidwolinsky.com/2010/07/headaches-of-blocking-sockets.html
    +++ G: tcp send recv latency
      https://encrypted.google.com/search?q=tcp%20send%20recv%20latency
      G: (mosh): retain responsiveness, fill up network buffers
        => MAYBE Ctrl-C problem is related to SSH architecture itself ?
    + http://stackoverflow.com/questions/467396/can-the-server-use-the-same-socket-to-send-the-response-to-the-client-how
      TRY: shutdown(client_socket, SHUT_WR) to half-close socket and send message EOF
        ~ MAYBE has latency drawbacks from protocol/kernel compared to custom msg delimiters
  How can we verify that the server can still send messages through a socket to reach the client, without actually sending anything through that socket?
    :: You can't, unless you've enabled TCP keepalives.
    https://delog.wordpress.com/2013/08/16/handling-tcp-keepalive/
    http://www.digi.com/wiki/developer/index.php/Handling_Socket_Error_and_Keepalive
    http://note.artchiu.org/2014/07/10/how-to-change-tcp-keepalive-timer-using-python-script/
  UDP sockets
    https://www.cs.rutgers.edu/~pxk/417/notes/sockets/udp.html
  C -- event loop
    http://software.schmorp.de/pkg/libev.html
      http://pod.tst.eu/http://cvs.schmorp.de/libev/ev.pod
      http://www.win.tue.nl/~aeb/linux/lk/lk-12.html
  socket send by DMA to buffer
    https://www.quora.com/How-can-you-do-DMA-between-an-user-space-buffer-and-a-socket
    https://codemonkeytips.blogspot.com/2011/07/zero-copy-network-transmission-with.html


!!! READ
  server architecture (G: socket connection architecture)
    2016-11-01 [X] http://berb.github.io/diploma-thesis/original/042_serverarch.html
      +++ http://berb.github.io/diploma-thesis/index.html
        = Cool overview for server/concurrency/scaling
      https://github.com/berb/diploma-thesis/tree/gh-pages
    https://www.tutorialspoint.com/unix_sockets/client_server_model.htm
    http://www.codeproject.com/Articles/990474/Scalable-Socket-Server
    http://caml.inria.fr/pub/docs/oreilly-book/html/book-ora187.html
    http://cis-linux1.temple.edu/~giorgio/cis307/readings/unix4.html
    https://pymotw.com/2/socket/tcp.html
    http://www.softwaretestingclass.com/what-is-difference-between-two-tier-and-three-tier-architecture/
    http://www.isi.edu/touch/pubs/infocomm99/infocomm99-web/
  CouchDB definitive guide
    http://guide.couchdb.org/
  Protocol Design Notes
    http://www.linuxtopia.org/online_books/programming_books/python_programming/python_ch36s06.html?
    FTP
      two connections == ASCII commands control connection and Binary data transfer
      http://stackoverflow.com/questions/18700840/why-we-need-two-connections-between-the-ftp-server-and-the-ftp-client
    waka
      http://berb.github.io/diploma-thesis/original/091_archtrends.html#waka
        http://tools.ietf.org/agenda/83/slides/slides-83-httpbis-5.pdf
    SPDY
      http://berb.github.io/diploma-thesis/original/091_archtrends.html#spdy
    !! Event sourcing and CQRS
      http://berb.github.io/diploma-thesis/original/091_archtrends.html#escqrs
        = seems like what I desire to build
        ru: http://blog.byndyu.ru/2014/07/command-and-query-responsibility.html
        http://www.baeldung.com/cqrs-event-sourced-architecture-resources
        http://blog.jonathanoliver.com/why-i-still-love-cqrs-and-messaging-and-event-sourcing/
        http://docs.geteventstore.com/
        https://elixirforum.com/t/ddd-cqrs-es-nosql-and-functional-programming/519
        https://softwaremill.com/entry-level-event-sourcing/
        http://softwareengineering.stackexchange.com/questions/294715/what-are-the-differences-between-event-sourcing-and-service-layer-pattern
        http://blog.langer.eu/2014/09/02/literature.html
      Event Sourcing
      * http://martinfowler.com/eaaDev/EventSourcing.html
          https://ookami86.github.io/event-sourcing-in-practice/#event-sourcing-vs-active-record/01-event-sourcing-vs-active-record.md
          https://craigsmith.id.au/2016/03/29/martin-fowler-on-microservices-event-sourcing-and-infrastructure-as-code/
          http://thinkbeforecoding.com/post/2013/07/28/Event-Sourcing-vs-Command-Sourcing
          http://blog.arkency.com/2015/03/why-use-event-sourcing/
      CQRS : Command Query Responsibility Segregation
      * http://udidahan.com/2009/12/09/clarified-cqrs/
          https://jeremywsherman.com/blog/2013/12/20/clarified-cqrs-reading-notes/
          http://udidahan.com/2011/04/22/when-to-avoid-cqrs/
          http://udidahan.com/wp-content/uploads/Clarified_CQRS.pdf
          audio: http://www.se-radio.net/2015/01/episode-218-udi-dahan-on-cqrs-command-query-responsibility-segregation/
          + https://en.wikipedia.org/wiki/Command%E2%80%93query_separation
  READ:ALSO:
    G: tcp socket duplex latency
      2016-11-02 [35%] https://blog.cloudflare.com/revenge-listening-sockets/
      System tap scripts -- meashure soft IRQ function
        https://github.com/cloudflare/cloudflare-blog/tree/master/2016-04-bind-to-star
      http://tpierrain.blogspot.com/2013/09/some-web-mechanical-sympathy-lets.html
    G: tcp send both
      2016-11-02 [X] http://stackoverflow.com/questions/467396/can-the-server-use-the-same-socket-to-send-the-response-to-the-client-how


Spec
  minimal (optimal) resource usage
  immediate reaction on clients messages
    single thread event-driven has delay
      * FIFO -- until msg queue exhausted
      * priority queue -- until current transaction ends
    single thread simplex communication
      * queue unsupported
      * delay until transaction ends and returns to listening
  is there need for servers on both sides?
    we can use pull-only connect from client
      if send long file to server -- use separate thread
  open direct socket : preview <--> ui
    for cached preview -- need separate mgmt entity
      * preview threads pool
      * cache db mgmt / garbage-collecting
      * transmitting preview
        broadcasting *core* sockets == connect to receive
        OR sink *ui* sockets == connect to send
        = even if preview_mgmt linked to *core* == it opens/manages its own socket to send data
          # except when *preview* completely linked to *ui* == then direct memory usage
      BAD: big preview re-displaying
        slow to generate preview (CPU/IO bound)
          ! want to access already cached preview when reconnecting *ui*
          => NEED cache on target side
        repeated additional net traffic
          ! want to minimize traffic
          => NEED cache on host side
        slow to display -- wait until transmitted, show after
          ! want immediate preview of cached entries
          => NEED cache directly in *ui* (or DMA/shared mem with host's *preview/db* conterpart)
    for preview on host's side -- need second mgmt entity
      target one sends binary files to process
      host one makes preview and caches it in its own db
      then shows cached preview on each host request
      rebuilds review for file
        when *cursor* requests content (cursor over file)
        and *core* confirms that file was changed
      BUT: multiple *cursor* must reuse the same *preview/db*
        you need proxy *core* on host's side for all *cursor* to connect to
          MAYBE: create separate lightweight entity *proxy* for such occasions?
          * proxy *core* has no access to host fs
          * proxy *core* connects to real remote *core* to provide *dom*
    no need to traverse data through all *mod*
      * less CPU usage on re-transmitting
      * more responsiveness
      * specialized commands-only protocol
        must send sync-chunks for *dom*/*frame*
        ??? which cmds server thinks important enough to send when it transmits *dom* ???
    !! NAT/firewall support
        all *mod* traversing by creating parallel sockets for preview transmission
          + useful for penetrating multiple firewalls at once
          - additional ports may be closed / unavailable
          - at least +1 thread to each process
        send preview through command socket
          useful for small text-only preview in highly restricted environment
          - impossible signals from *core* until preview transmitted
          => so, enable this option only on demand and toggle only temporarily


preview _vs_ accessors
  ? different or the same ?
  preview
    cache: large compressed database
      = can be stored on separate server ?
    accent: processed file content
    representation: big binary blob
  accessors
    cache: relatively small dom
      = has sense only in immediate context
    accent: entries lists
    representation: part of *dom* itself
      fs metainfo
      results of ops (*ag*, etc)
      virtual tree (converted outline, *ag* results, etc)


State Synchronization Protocol (SSP)
  [_] TODO: look at 'mosh' internals
    https://github.com/mobile-shell/mosh
    ~ 6k lines in {crypto,network,protobufs,util}
  READ: Technical details on SSP protocol
    https://mosh.org/#techinfo
    = UDP datagrams are encrypted and authenticated using AES-128 in OCB mode.
    = synchronizing the state of any object from one host to another
  [_] TRY: implement SSP for frames sync from *dom*
  SEE:IDEA
    https://en.wikipedia.org/wiki/WASTE


THINK
  ! allow enable socket server / choose *relay* after startup by options
    E.G. enable control for *gui* colorscheme to control from outside
    => each *mod* must have 'dispatcher' for commands :: functions
  *core* must notify *ui* when /dir/* changed to reload view
    ? is it possible in current socket model, when server only inside *core* ?
    ? use 'dbus' ?
  Thin relay: 'preview image' --> *ui*
    ++ SEE: IPC : shared memory
      = render image directly into memory, displayed by *ui* for preview
      = like render into opengl second buffer
    + we need to deliver info onto screen anyway
      => be it relaying through *core* or directly
      * image/data must be aquired/generated
      * results must be outputted
        - container (memory, file, pipe, etc)
          = must be interpreted before displaying
          SEE:(mail://dev@suckless.org) universal format for image displaying, as 'feh' ALT
        - or directly to screen
          = has appeal only when greatly optimized
    ? how to do it fast ?
      < high cpu load on image transmition through socket
      ! NEED direct access
        direct memory access
        GPU memory
        X apps embedding (like already existing viewer)
          then *miur* controls only 'bonding/setup' of apps
        ! pipes/shared_mem --> faster then socket
          [_] SEE: 'multiprocessing' -- integrates api for cross-platform IPC
    THINK: *core*/*ui* on different machines
      ? heuristic what is faster
        ~ generate preview on target and send image to host
        ~ send file itself (or its parts) to host and generate preview there

  Distributed model
    ? How to provide cross-communication ?
    *core* -- target
    *ui* -- host
    *preview* -- positioned completely on 3rd-party server
      like 3d rendering
      conveys only resulting images / analytics
    Distributed protocols
      * sync *proj* between *ui*
      * exchange data between *core*'s
      bittorrent

  Serialization
    E.G.
      JSON
      pickle
    compress tree structures
    snapshot diff

  Transparency (no socket)
    (option) tight-coupling of modules written in single language
      eliminate socket/serialization stuff in-between of them
    Essential for fast startup/shutdown
      server shutdown itself is 'SLOW' ~0.5s

  Client passive listening
    = NEED to wait on 'state update' signal from server
    http://users.pja.edu.pl/~jms/qnx/help/tcpip_4.25_en/prog_guide/sock_advanced_tut.html

connect to same background ranger instance on demand
  on demand make standalone as server
  distributed model -- any instance can be server
  many different *gui* can connect to single '*core*'

launch new instance from inside current manager
  > keep it independent
  > connect it to server automatically to share info

MAYBE when spawning shell -- don't use it as child
  - keep *core* working as server
  - close interface completely
  - run commands directly in the underlying shell
  - launch and connect interface again

keep background interactive shell (eliminate its startup time)
  = seems like I need nvim-like virtual terminal to virtualize IA with term escape codes
  * add '-s' server flag to :shell and make it DFL
  * replace entering into shell by switching to already launched one (with scrollback?)
